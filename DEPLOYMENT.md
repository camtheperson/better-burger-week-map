# Burger Week Map - Deployment Guide

## ğŸš€ Quick Start

### Local Development
```bash
npm install
npm run scrape      # Get latest burger data
npm run dev        # Start development server at http://localhost:8080
```

### Building for Production
```bash
npm run build      # Creates ./dist folder with all assets
npm run deploy     # Deploy to GitHub Pages (requires setup)
```

## ğŸ“Š Data Management

### Scraping Data
The scraper collects restaurant information from EverOut:
```bash
npm run scrape     # Scrapes all burger week data
```

### Adding Coordinates
Some restaurants may need manual geocoding:
```bash
npm run add-coords # Adds known coordinates to restaurants
```

## ğŸŒ Deployment Options

### GitHub Pages (Recommended)
1. **Automatic Deployment**:
   - Push to `main` branch
   - GitHub Actions automatically scrapes and deploys
   - Site updates daily at 8 AM UTC

2. **Manual Deployment**:
   ```bash
   npm run deploy
   ```

### Other Static Hosts
The built files in `./dist` can be deployed to:
- Netlify
- Vercel
- Firebase Hosting
- Any static file host

## ğŸ”§ Configuration

### Environment Variables
For production deployment, you may want to set:
```bash
DOMAIN=your-custom-domain.com  # For custom domain setup
```

### GitHub Pages Setup
1. Enable GitHub Pages in repository settings
2. Source: GitHub Actions
3. The workflow will handle everything automatically

## ğŸ“ Project Structure
```
burger-week-map/
â”œâ”€â”€ index.html          # Main HTML file
â”œâ”€â”€ style.css          # Styling
â”œâ”€â”€ app.js             # Frontend JavaScript
â”œâ”€â”€ data/              # JSON data files
â”‚   â”œâ”€â”€ burgers.json   # Restaurant data
â”‚   â””â”€â”€ summary.json   # Summary statistics
â”œâ”€â”€ scripts/           # Build and utility scripts
â”‚   â”œâ”€â”€ scraper.js     # Web scraper
â”‚   â”œâ”€â”€ add-coordinates.js  # Coordinate helper
â”‚   â””â”€â”€ build.sh       # Build script
â”œâ”€â”€ .github/workflows/ # GitHub Actions
â””â”€â”€ dist/             # Built files (generated)
```

## ğŸ› ï¸ Troubleshooting

### Scraper Issues
- **Rate limiting**: The scraper includes delays to respect servers
- **URL errors**: Check the base URL in `scraper.js`
- **Geocoding blocked**: We skip geocoding by default to avoid blocks

### Deployment Issues
- **GitHub Pages**: Check Actions tab for deployment status
- **404 errors**: Ensure `404.html` is in the root directory
- **Map not loading**: Check browser console for errors

### Development Issues
- **Map not showing**: Verify `data/burgers.json` exists and is valid
- **No markers**: Check that some restaurants have latitude/longitude
- **CORS errors**: Use the development server, not file:// URLs

## ğŸ”„ Maintenance

### Daily Updates
The GitHub Action runs daily to keep data fresh:
- Scrapes latest restaurant information
- Updates geocoding for new restaurants
- Rebuilds and deploys the site

### Manual Updates
To manually update data:
```bash
npm run scrape     # Get fresh data
npm run build      # Build site
npm run deploy     # Deploy changes
```

## ğŸ“ˆ Analytics & Monitoring

### Adding Analytics
Add your analytics code to `index.html`:
```html
<!-- Google Analytics, Plausible, etc. -->
```

### Monitoring
- Check GitHub Actions for scraping issues
- Monitor site performance via hosting provider
- Watch for 404s in analytics

## ğŸ¨ Customization

### Styling
Edit `style.css` to change:
- Colors and themes
- Layout and spacing
- Responsive behavior

### Functionality
Edit `app.js` to modify:
- Map behavior
- Search and filtering
- Modal content

### Data Sources
Edit `scripts/scraper.js` to:
- Change data source URLs
- Add new data fields
- Modify parsing logic

## ğŸ¤ Contributing

1. Fork the repository
2. Make your changes
3. Test locally with `npm run dev`
4. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details
